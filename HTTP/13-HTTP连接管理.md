# 连接管理

## 短连接

因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“**短连接**”（short-lived connections）。**早期的 HTTP 协议也被称为是“无连接”的协议。**

短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有“三次握手”，发送 3 个数据包，需要 1 个 RTT；关闭连接是“四次挥手”，4 个数据包需要 2 个 RTT。

## 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了“**长连接**”的通信方式，也叫“**持久连接**”（persistent connections）、“**连接保活**”（keep alive）、“**连接复用**”（connection reuse）

[长短链接对比](../images/长短连接对比图.png)

## 连接相关的头字段

由于长连接对性能的改善效果非常显著，所以在 **HTTP/1.1 中的连接都会默认启用长连接**

可以在请求头里明确地要求使用长连接机制，使用的字段是 **Connection**，值是“**keep-alive**”。

不过不管客户端是否显式要求长连接，如果服务器支持长连接，它总会在响应报文里放一个“**Connection: keep-alive**”字段，告诉客户端：“我是支持长连接的，接下来就用这个 TCP 一直收发数据吧”。

在客户端，可以在请求头里加上“**Connection: close**”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也加上这个字段，发送之后就调用 Socket API 关闭 TCP 连接。

服务器端通常不会主动关闭连接，但也可以使用一些策略。拿 Nginx 来举例，它有两种方式：

1. 使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
2. 使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

## 队头阻塞

“队头阻塞”与短连接和长连接无关，而是由 HTTP 基本的“**请求 - 应答**”模型所导致的。

因为 HTTP 规定报文必须是“一发一收”，这就形成了一个**先进先出的“串行”队列**。**队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理**。

[队首阻塞](../images/队头阻塞.png)

## 性能优化

 HTTP 里就是“**并发连接**”（concurrent connections），也就是同时对一个域名发起多个长连接，用数量来解决质量的问题,缓解队首阻塞

 域名分片”（domain sharding）技术,还是用数量来解决质量的思路.HTTP 协议和浏览器不是限制并发连接数量吗？好，那我就多开几个域名，比如 shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器 www.chrono.com，这样实际长连接的数量就又上去了，真是“美滋滋”。不过实在是有点“上有政策，下有对策”的味道。
